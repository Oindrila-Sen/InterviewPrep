{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn - a one stop solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "iris = datasets.load_iris()\n",
    "print(iris.data.shape)\n",
    "print(iris.feature_names)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "house_dtls = datasets.load_boston()\n",
    "print(house_dtls.data.shape)\n",
    "print(house_dtls.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "print(newsgroups_train.filenames.shape)\n",
    "newsgroups_train.data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data X shape is (100, 20)\n",
      "The data y shape is (100,)\n"
     ]
    }
   ],
   "source": [
    "X,y = datasets.make_classification(n_features=20,\n",
    "                                   n_samples=100,\n",
    "                                   n_redundant=0, \n",
    "                                   n_informative=5,\n",
    "                                   n_clusters_per_class=1\n",
    "                                  )\n",
    "print(\"The data X shape is {}\".format(X.shape))\n",
    "print(\"The data y shape is {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data X shape is (100, 20)\n",
      "The data y shape is (100, 3)\n"
     ]
    }
   ],
   "source": [
    "A, b = datasets.make_multilabel_classification(n_classes=3, \n",
    "                                               allow_unlabeled=True,\n",
    "                                               random_state=1)\n",
    "print(\"The data X shape is {}\".format(A.shape))\n",
    "print(\"The data y shape is {}\".format(b.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression data X shape is (100, 1)\n",
      "The regression data y shape is (100,)\n"
     ]
    }
   ],
   "source": [
    "X, y = datasets.make_regression(n_features=1, n_informative=1)\n",
    "print(\"The regression data X shape is {}\".format(X.shape))\n",
    "print(\"The regression data y shape is {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit:  MinMaxScaler()\n",
      "Max:  [ 90. 188.]\n",
      "Transform:  [[0.         0.40206186]\n",
      " [0.00549451 0.        ]\n",
      " [1.         0.08247423]\n",
      " [0.12087912 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = [[-1, 72], [-0.5, -6], [90, 10], [10, 188]]\n",
    "scaler = MinMaxScaler() \n",
    "print(\"Fit: \", scaler.fit(data))\n",
    "print(\"Max: \", scaler.data_max_)\n",
    "print(\"Transform: \" , scaler.transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit:  StandardScaler()\n",
      "Mean:  [0.5 0.5]\n",
      "Transform:  [[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "print(\"Fit: \", scaler.fit(data))\n",
    "print(\"Mean: \", scaler.mean_)\n",
    "print(\"Transform: \" , scaler.transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2, 0.4, 0.4],\n",
       "       [0.1, 0.3, 0.9, 0.3],\n",
       "       [0.5, 0.7, 0.5, 0.1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "X = [[4, 1, 2, 2],\n",
    "      [1, 3, 9, 3],\n",
    "      [5, 7, 5, 1]]\n",
    "transformer = Normalizer().fit(X)  \n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data\n",
      "[['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
      "The transform data using OrdinalEncoder\n",
      "[[0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "print(\"The original data\")\n",
    "print(X)\n",
    "print(\"The transform data using OrdinalEncoder\")\n",
    "print(enc.transform([['female', 'from US', 'uses Safari']]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data\n",
      "[['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
      "The transform data using OneHotEncoder\n",
      "[[1. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "print(\"The original data\")\n",
    "print(X)\n",
    "print(\"The transform data using OneHotEncoder\")\n",
    "print(enc.transform([['female', 'from US', 'uses Safari'],\n",
    "                ['male', 'from Europe', 'uses Safari']]).toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data\n",
      "['Sun' 'Sun' 'Moon' 'Earth' 'Monn' 'Venus']\n",
      "The transform data using LabelEncoder\n",
      "[3 3 2 0 1 4]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "import numpy as np\n",
    "\n",
    "targets = np.array([\"Sun\", \"Sun\", \"Moon\", \"Earth\", \"Monn\", \"Venus\"])\n",
    "labelenc = preprocessing.LabelEncoder()\n",
    "labelenc.fit(targets)\n",
    "targets_trans = labelenc.transform(targets)\n",
    "print(\"The original data\")\n",
    "print(targets)\n",
    "print(\"The transform data using LabelEncoder\")\n",
    "print(targets_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Features Count:  64\n",
      "Features count after using SelectKBest:  20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(\"Orginal Features Count: \", X.shape[1])\n",
    "\n",
    "X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n",
    "print(\"Features count after using SelectKBest: \", X_new.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "The processed data by variance threshold\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "import numpy as np \n",
    "\n",
    "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1,\n",
    "                                                                      1]])\n",
    "var = fs.VarianceThreshold(threshold=0.2)\n",
    "var.fit(X)\n",
    "X_trans = var.transform(X)\n",
    "print(\"The original data\")\n",
    "print(X)\n",
    "print(\"The processed data by variance threshold\")\n",
    "print(X_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get all the feature names of this corpus\n",
      "['an', 'apple', 'have', 'is', 'like', 'nutritous', 'red', 'the']\n",
      "The number of feature is 8\n",
      "The transform data's shape is (4, 8)\n",
      "[[1 1 1 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 1]\n",
      " [0 1 0 0 1 0 0 1]\n",
      " [0 1 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counterVec = CountVectorizer()\n",
    "# corpus is a list of string in this example, such as:\n",
    "corpus = [\n",
    "    \"I have an apple.\",\n",
    "    \"The apple is red\",\n",
    "    \"I like the apple\",\n",
    "    \"Apple is nutritous\"\n",
    "    ]\n",
    "counterVec.fit(corpus)\n",
    "# corpus_data is a matrix with 0/1.\n",
    "corpus_data = counterVec.transform(corpus)\n",
    "print(\"Get all the feature names of this corpus\")\n",
    "print(counterVec.get_feature_names())\n",
    "print(\"The number of feature is {}\".format(len(counterVec.get_feature_names())))\n",
    "corpus_data = counterVec.transform(corpus)\n",
    "print(\"The transform data's shape is {}\".format(corpus_data.toarray().shape))\n",
    "print(corpus_data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2, 3)\n",
      "[[[ 0  3]\n",
      "  [12 15]]\n",
      "\n",
      " [[15 18]\n",
      "  [27 30]]]\n",
      "(9, 2, 2, 3)\n",
      "[[15 18]\n",
      " [27 30]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "one_image = np.arange(4 * 4 * 3).reshape((4, 4, 3))\n",
    "one_image[:, :, 0]  # R channel of a fake RGB picture\n",
    "patches = image.extract_patches_2d(one_image, (2, 2), max_patches=2,random_state=0)\n",
    "print(patches.shape)\n",
    "print(patches[:, :, :, 0])\n",
    "patches = image.extract_patches_2d(one_image, (2, 2))\n",
    "print(patches.shape)\n",
    "print(patches[4, :, :, 0])\n",
    "reconstructed = image.reconstruct_from_patches_2d(patches, (4, 4, 3))\n",
    "np.testing.assert_array_equal(one_image, reconstructed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
